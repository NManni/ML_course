{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Questions: \n",
    "Column of X~ : the column of 1 is here for the bias term, and the second column is the height of every person\n",
    "Rows of X~ : each row correspond to a person's height\n",
    "1's in X~ : the 1's column is here so that we can multiply the w = [w0, w1] matrix with X~\n",
    "3 people:  y = 3x1 and X~ = 3x2 , with X32 being the height of the third person\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss by MSE\n",
    "    N = len(y)\n",
    "    Xw = tx @ w\n",
    "    MSE = (1 / (2 * N) ) * np.sum((y[:] - Xw[:])**2)\n",
    "    return MSE\n",
    "    # ***************************************************\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2694.4833658870843\n"
     ]
    }
   ],
   "source": [
    "w = np.array([1, 2])\n",
    "MSE = compute_loss(y, tx, w)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute loss for each combination of w0 and w1.\n",
    "    for i in range(len(grid_w0)): \n",
    "        for j in range(len(grid_w1)): \n",
    "            w = np.array([grid_w0[i], grid_w1[j]])\n",
    "            losses[i][j] = compute_loss(y, tx, w)\n",
    "    # ***************************************************\n",
    "    #raise NotImplementedError\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=42.42448314678248, w0*=66.66666666666669, w1*=16.666666666666686, execution time=0.127 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        An numpy array of shape (2, ) (same shape as w), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute gradient vector\n",
    "    e = y - tx @ w\n",
    "    gradient = - (1 / len(y) ) * (tx.T @ e)\n",
    "    return gradient\n",
    "    # ***************************************************\n",
    "    #raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.293922  , -0.47971243])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.array([72, 13])\n",
    "compute_gradient(y, tx, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute gradient and loss\n",
    "        gradient= compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        # ***************************************************\n",
    "        #raise NotImplementedError\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        w = w - gamma * gradient\n",
    "        # ***************************************************\n",
    "        #raise NotImplementedError\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=5761.326249239219, w0=16.329392200210528, w1=91.3479712434989\n",
      "GD iter. 1/49: loss=4669.597580578844, w0=22.025845180400026, w1=83.56114536264788\n",
      "GD iter. 2/49: loss=3785.297358963937, w0=27.152652862570555, w1=76.55300206988198\n",
      "GD iter. 3/49: loss=3069.0141794558654, w0=31.766779776524018, w1=70.24567310639272\n",
      "GD iter. 4/49: loss=2488.82480405433, w0=35.919493999082135, w1=64.56907703925236\n",
      "GD iter. 5/49: loss=2018.8714099790857, w0=39.65693679938447, w1=59.46014057882602\n",
      "GD iter. 6/49: loss=1638.2091607781356, w0=43.02063531965655, w1=54.862097764442325\n",
      "GD iter. 7/49: loss=1329.872738925367, w0=46.047963987901426, w1=50.723859231496995\n",
      "GD iter. 8/49: loss=1080.1202372246244, w0=48.772559789321804, w1=46.9994445518462\n",
      "GD iter. 9/49: loss=877.8207108470235, w0=51.22469601060015, w1=43.647471340160486\n",
      "GD iter. 10/49: loss=713.9580944811664, w0=53.43161860975066, w1=40.63069544964335\n",
      "GD iter. 11/49: loss=581.2293752248224, w0=55.41784894898611, w1=37.91559714817791\n",
      "GD iter. 12/49: loss=473.7191126271835, w0=57.20545625429803, w1=35.472008676859026\n",
      "GD iter. 13/49: loss=386.6357999230962, w0=58.81430282907875, w1=33.27277905267202\n",
      "GD iter. 14/49: loss=316.09831663278527, w0=60.2622647463814, w1=31.293472390903716\n",
      "GD iter. 15/49: loss=258.9629551676334, w0=61.56543047195378, w1=29.512096395312245\n",
      "GD iter. 16/49: loss=212.68331238086057, w0=62.738279624968925, w1=27.908857999279924\n",
      "GD iter. 17/49: loss=175.19680172357457, w0=63.79384386268256, w1=26.465943442850836\n",
      "GD iter. 18/49: loss=144.83272809117292, w0=64.74385167662483, w1=25.167320342064656\n",
      "GD iter. 19/49: loss=120.23782844892757, w0=65.59885870917286, w1=23.99855955135709\n",
      "GD iter. 20/49: loss=100.31595973870893, w0=66.3683650384661, w1=22.946674839720284\n",
      "GD iter. 21/49: loss=84.17924608343179, w0=67.06092073483, w1=21.999978599247157\n",
      "GD iter. 22/49: loss=71.10850802265729, w0=67.68422086155752, w1=21.147951982821343\n",
      "GD iter. 23/49: loss=60.52121019342999, w0=68.24519097561229, w1=20.38112802803812\n",
      "GD iter. 24/49: loss=51.94549895175591, w0=68.75006407826159, w1=19.69098646873321\n",
      "GD iter. 25/49: loss=44.99917284599982, w0=69.20444987064594, w1=19.06985906535879\n",
      "GD iter. 26/49: loss=39.372648700337436, w0=69.61339708379187, w1=18.51084440232182\n",
      "GD iter. 27/49: loss=34.81516414235094, w0=69.9814495756232, w1=18.00773120558854\n",
      "GD iter. 28/49: loss=31.123601650381822, w0=70.3126968182714, w1=17.55492932852859\n",
      "GD iter. 29/49: loss=28.133436031886845, w0=70.61081933665479, w1=17.147407639174634\n",
      "GD iter. 30/49: loss=25.711401880905917, w0=70.87912960319983, w1=16.780638118756077\n",
      "GD iter. 31/49: loss=23.749554218611376, w0=71.12060884309037, w1=16.450545550379374\n",
      "GD iter. 32/49: loss=22.160457612152797, w0=71.33794015899184, w1=16.15346223884034\n",
      "GD iter. 33/49: loss=20.873289360921365, w0=71.53353834330318, w1=15.88608725845521\n",
      "GD iter. 34/49: loss=19.83068307742389, w0=71.70957670918338, w1=15.645449776108595\n",
      "GD iter. 35/49: loss=18.986171987790932, w0=71.86801123847556, w1=15.42887604199664\n",
      "GD iter. 36/49: loss=18.30211800518824, w0=72.01060231483852, w1=15.23395968129588\n",
      "GD iter. 37/49: loss=17.748034279280063, w0=72.13893428356519, w1=15.058534956665197\n",
      "GD iter. 38/49: loss=17.299226461294438, w0=72.2544330554192, w1=14.900652704497581\n",
      "GD iter. 39/49: loss=16.93569212872607, w0=72.3583819500878, w1=14.758558677546729\n",
      "GD iter. 40/49: loss=16.641229319345697, w0=72.45193595528954, w1=14.630674053290962\n",
      "GD iter. 41/49: loss=16.402714443747605, w0=72.5361345599711, w1=14.51557789146077\n",
      "GD iter. 42/49: loss=16.20951739451315, w0=72.61191330418451, w1=14.411991345813599\n",
      "GD iter. 43/49: loss=16.053027784633237, w0=72.68011417397658, w1=14.318763454731144\n",
      "GD iter. 44/49: loss=15.92627120063051, w0=72.74149495678944, w1=14.234858352756934\n",
      "GD iter. 45/49: loss=15.823598367588298, w0=72.79673766132102, w1=14.159343760980144\n",
      "GD iter. 46/49: loss=15.740433372824103, w0=72.84645609539943, w1=14.091380628381035\n",
      "GD iter. 47/49: loss=15.673069727065116, w0=72.89120268607, w1=14.030213809041836\n",
      "GD iter. 48/49: loss=15.61850517400033, w0=72.93147461767352, w1=13.975163671636558\n",
      "GD iter. 49/49: loss=15.574307886017857, w0=72.96771935611669, w1=13.925618547971807\n",
      "GD: execution time=0.018 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([10, 100])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2264170d762e45e4a56b3586bf9a9f5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *\n",
    "\n",
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: implement stochastic gradient computation. It's the same as the usual gradient.\n",
    "    e = y - tx @ w\n",
    "    gradient = - (1 / len(y) ) * (tx.T @ e)\n",
    "    return gradient\n",
    "    # ***************************************************\n",
    "    #raise NotImplementedError\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        yB, txB = next(batch_iter(y, tx, batch_size, num_batches=1, shuffle=True))\n",
    "        gradient= compute_gradient(yB, txB, w)\n",
    "        loss = compute_loss(yB, txB, w)\n",
    "        w = w - gamma * gradient\n",
    "        # ***************************************************\n",
    "        #raise NotImplementedError\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=3132.989783341298, w0=7.915794064200127, w1=1.6608068861950878\n",
      "SGD iter. 1/49: loss=3125.507857760281, w0=15.82213058342353, w1=9.957243372275\n",
      "SGD iter. 2/49: loss=1140.4249171297422, w0=20.597954946043544, w1=7.7210415566202215\n",
      "SGD iter. 3/49: loss=1572.700101883225, w0=26.206341704966693, w1=6.118747966400355\n",
      "SGD iter. 4/49: loss=622.1022968817919, w0=29.733670146951624, w1=-2.63262719476979\n",
      "SGD iter. 5/49: loss=1671.7723923338158, w0=35.516009452689076, w1=-0.512465760355743\n",
      "SGD iter. 6/49: loss=1911.6355726900945, w0=41.699270037024974, w1=8.304641355718848\n",
      "SGD iter. 7/49: loss=679.3252679675634, w0=45.38525774174555, w1=6.8067881412599\n",
      "SGD iter. 8/49: loss=351.07556166401906, w0=48.03507117541977, w1=7.009844380673164\n",
      "SGD iter. 9/49: loss=438.95592364001635, w0=50.998028899181676, w1=6.221341149091812\n",
      "SGD iter. 10/49: loss=85.07130281682426, w0=52.30241613322549, w1=3.7833465658907195\n",
      "SGD iter. 11/49: loss=248.84238152169263, w0=54.53330107656835, w1=5.671918406767286\n",
      "SGD iter. 12/49: loss=164.19200595304176, w0=56.34543796959294, w1=6.819821366614282\n",
      "SGD iter. 13/49: loss=136.31238155946673, w0=57.996573224861066, w1=6.893037295912482\n",
      "SGD iter. 14/49: loss=154.67348541605284, w0=59.755399455141095, w1=6.6150139313705125\n",
      "SGD iter. 15/49: loss=0.25789527053462574, w0=59.82721801409832, w1=6.581649260480827\n",
      "SGD iter. 16/49: loss=183.6336793423774, w0=61.743640093612, w1=7.949611470792341\n",
      "SGD iter. 17/49: loss=15.743634416785412, w0=61.18250491530315, w1=8.495853417426982\n",
      "SGD iter. 18/49: loss=18.099862256623776, w0=61.78416698418607, w1=7.42637841301445\n",
      "SGD iter. 19/49: loss=74.52706109720636, w0=63.00504421877771, w1=8.573420441965443\n",
      "SGD iter. 20/49: loss=149.9682733660773, w0=64.73691184285339, w1=9.066525655450093\n",
      "SGD iter. 21/49: loss=39.63223369218828, w0=65.62721778680961, w1=9.618345953984823\n",
      "SGD iter. 22/49: loss=1.4218147583211782, w0=65.45858713963531, w1=9.645153195819711\n",
      "SGD iter. 23/49: loss=263.7550612052739, w0=67.75534599160595, w1=10.860691311822288\n",
      "SGD iter. 24/49: loss=0.026650470963254163, w0=67.73225899484879, w1=10.859719584728678\n",
      "SGD iter. 25/49: loss=2.338532709797143, w0=67.51599375447036, w1=11.15529037920728\n",
      "SGD iter. 26/49: loss=63.301974622330924, w0=68.64117795825506, w1=10.855856008715456\n",
      "SGD iter. 27/49: loss=0.8831408255246995, w0=68.77407948763111, w1=10.839539437496498\n",
      "SGD iter. 28/49: loss=4.48284085412456, w0=69.0735069698075, w1=10.875921485595248\n",
      "SGD iter. 29/49: loss=91.70978293106877, w0=70.42783176786052, w1=14.118654786963795\n",
      "SGD iter. 30/49: loss=0.2208311065737906, w0=70.36137409613275, w1=14.105988386653745\n",
      "SGD iter. 31/49: loss=1.9467373980937683, w0=70.55869299528302, w1=14.048214050656682\n",
      "SGD iter. 32/49: loss=3.1158991249815027, w0=70.30905729571337, w1=14.23422306953322\n",
      "SGD iter. 33/49: loss=8.591342060976594, w0=70.72357730876405, w1=14.187871578640534\n",
      "SGD iter. 34/49: loss=12.846924519777243, w0=71.23046831321722, w1=12.921748567397024\n",
      "SGD iter. 35/49: loss=3.772018069529872, w0=71.50513240149706, w1=12.781086051723666\n",
      "SGD iter. 36/49: loss=13.680751503783272, w0=72.0282146417573, w1=12.136589876144223\n",
      "SGD iter. 37/49: loss=1.9265056859357375, w0=71.83192375119252, w1=12.26898440949809\n",
      "SGD iter. 38/49: loss=16.94695487023542, w0=71.24973898893512, w1=12.484619783992114\n",
      "SGD iter. 39/49: loss=13.8334456431898, w0=71.7757322520705, w1=12.03981276360772\n",
      "SGD iter. 40/49: loss=0.024482021792861578, w0=71.75360443166592, w1=11.995064646391407\n",
      "SGD iter. 41/49: loss=0.5274757357297479, w0=71.85631526222724, w1=11.995779680946965\n",
      "SGD iter. 42/49: loss=28.41661641570273, w0=72.61019345418802, w1=13.170644332528136\n",
      "SGD iter. 43/49: loss=6.064911476924148, w0=72.26191450056251, w1=12.88228215605762\n",
      "SGD iter. 44/49: loss=11.086083064494742, w0=71.79104120413353, w1=13.807290112289051\n",
      "SGD iter. 45/49: loss=5.222746422175933, w0=72.11423608101668, w1=13.591727306095539\n",
      "SGD iter. 46/49: loss=43.00553348683232, w0=73.0416575977698, w1=14.022005284714334\n",
      "SGD iter. 47/49: loss=2.956900782525758, w0=72.79847450697088, w1=14.33105687567723\n",
      "SGD iter. 48/49: loss=37.10059953441888, w0=71.93707332825774, w1=13.033809628649719\n",
      "SGD iter. 49/49: loss=0.9387643820470111, w0=72.07409627393086, w1=13.121810896240136\n",
      "SGD: execution time=0.003 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0]), array([7.91579406, 1.66080689]), array([15.82213058,  9.95724337]), array([20.59795495,  7.72104156]), array([26.2063417 ,  6.11874797]), array([29.73367015, -2.63262719]), array([35.51600945, -0.51246576]), array([41.69927004,  8.30464136]), array([45.38525774,  6.80678814]), array([48.03507118,  7.00984438]), array([50.9980289 ,  6.22134115]), array([52.30241613,  3.78334657]), array([54.53330108,  5.67191841]), array([56.34543797,  6.81982137]), array([57.99657322,  6.8930373 ]), array([59.75539946,  6.61501393]), array([59.82721801,  6.58164926]), array([61.74364009,  7.94961147]), array([61.18250492,  8.49585342]), array([61.78416698,  7.42637841]), array([63.00504422,  8.57342044]), array([64.73691184,  9.06652566]), array([65.62721779,  9.61834595]), array([65.45858714,  9.6451532 ]), array([67.75534599, 10.86069131]), array([67.73225899, 10.85971958]), array([67.51599375, 11.15529038]), array([68.64117796, 10.85585601]), array([68.77407949, 10.83953944]), array([69.07350697, 10.87592149]), array([70.42783177, 14.11865479]), array([70.3613741 , 14.10598839]), array([70.558693  , 14.04821405]), array([70.3090573 , 14.23422307]), array([70.72357731, 14.18787158]), array([71.23046831, 12.92174857]), array([71.5051324 , 12.78108605]), array([72.02821464, 12.13658988]), array([71.83192375, 12.26898441]), array([71.24973899, 12.48461978]), array([71.77573225, 12.03981276]), array([71.75360443, 11.99506465]), array([71.85631526, 11.99577968]), array([72.61019345, 13.17064433]), array([72.2619145 , 12.88228216]), array([71.7910412 , 13.80729011]), array([72.11423608, 13.59172731]), array([73.0416576 , 14.02200528]), array([72.79847451, 14.33105688]), array([71.93707333, 13.03380963]), array([72.07409627, 13.1218109 ])]\n"
     ]
    }
   ],
   "source": [
    "print(sgd_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec9416a81d445438d7941519c270cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "# ***************************************************\n",
    "#raise NotImplementedError\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=2957.1379759153315, w0=53.83303090479882, w1=6.808149099407296\n",
      "SGD iter. 1/49: loss=35.599143319419454, w0=59.739566306625434, w1=3.557157078535266\n",
      "SGD iter. 2/49: loss=218.34631600940492, w0=74.36760068207099, w1=15.93493921942775\n",
      "SGD iter. 3/49: loss=24.8409410433333, w0=69.43362437259538, w1=18.36793289572622\n",
      "SGD iter. 4/49: loss=21.522976401870462, w0=74.02628339257858, w1=18.15516807425212\n",
      "SGD iter. 5/49: loss=5.9807294956472905, w0=71.6053094344918, w1=17.157390410719586\n",
      "SGD iter. 6/49: loss=12.854939972268177, w0=68.05596566798752, w1=16.253057567487787\n",
      "SGD iter. 7/49: loss=5.665878737915088, w0=70.4123529797758, w1=16.39554008310515\n",
      "SGD iter. 8/49: loss=32.91323403030872, w0=76.09169883556787, w1=16.698065138405973\n",
      "SGD iter. 9/49: loss=15.229102627373686, w0=72.22847213049008, w1=18.666795922541667\n",
      "SGD iter. 10/49: loss=2.0023912667374653, w0=73.62930882382828, w1=19.953423798634816\n",
      "SGD iter. 11/49: loss=2.1532818033961307, w0=75.08196713441897, w1=18.590247231670244\n",
      "SGD iter. 12/49: loss=61.04574690438231, w0=67.34731575466729, w1=3.532523002205517\n",
      "SGD iter. 13/49: loss=304.3659315942582, w0=84.61806017876125, w1=12.031413079227733\n",
      "SGD iter. 14/49: loss=171.13983551683182, w0=71.6674988470469, w1=25.61311674281955\n",
      "SGD iter. 15/49: loss=0.6347822154909541, w0=72.45622349556572, w1=25.222040036298637\n",
      "SGD iter. 16/49: loss=240.89972553532849, w0=87.82117487930338, w1=2.448675539323169\n",
      "SGD iter. 17/49: loss=49.7213494376032, w0=94.80164208779675, w1=12.547201188700937\n",
      "SGD iter. 18/49: loss=284.06815383510843, w0=78.11671503496231, w1=4.556835976131856\n",
      "SGD iter. 19/49: loss=25.802434236231786, w0=73.08815803006448, w1=5.348288586416257\n",
      "SGD iter. 20/49: loss=41.469325313918716, w0=79.4631042108287, w1=6.3848578117280255\n",
      "SGD iter. 21/49: loss=148.27345576060685, w0=67.40872796626944, w1=16.199877505374637\n",
      "SGD iter. 22/49: loss=18.446871500810072, w0=71.66054335158356, w1=19.29268351291011\n",
      "SGD iter. 23/49: loss=18.356714788238484, w0=67.41913079295716, w1=13.808082012319316\n",
      "SGD iter. 24/49: loss=0.00047883892666129337, w0=67.39746833353705, w1=13.802562661473772\n",
      "SGD iter. 25/49: loss=0.6383389350473547, w0=66.60653713782759, w1=14.192578842510693\n",
      "SGD iter. 26/49: loss=0.7115347016876656, w0=67.4415844464598, w1=13.687686067420213\n",
      "SGD iter. 27/49: loss=15.656211141999325, w0=71.35860971050384, w1=10.309161853661042\n",
      "SGD iter. 28/49: loss=3.2850117369362457, w0=73.15285370232812, w1=9.983597703339216\n",
      "SGD iter. 29/49: loss=0.2519707373777343, w0=73.64977554993615, w1=9.893431627916902\n",
      "SGD iter. 30/49: loss=35.34827396747781, w0=67.76408880256943, w1=10.106138374327038\n",
      "SGD iter. 31/49: loss=0.9239399958688987, w0=66.81253155471121, w1=11.172198854860536\n",
      "SGD iter. 32/49: loss=81.9388685637167, w0=75.77356336987862, w1=17.14513781939614\n",
      "SGD iter. 33/49: loss=19.70855107438618, w0=80.16837622742995, w1=18.679007389996553\n",
      "SGD iter. 34/49: loss=177.51211875403143, w0=66.97891542044655, w1=8.346110512741198\n",
      "SGD iter. 35/49: loss=46.544348211687954, w0=73.73268927270531, w1=14.178786411839411\n",
      "SGD iter. 36/49: loss=31.6287605023569, w0=79.30011105413249, w1=19.45307800460386\n",
      "SGD iter. 37/49: loss=59.12578985361865, w0=71.68806309996495, w1=22.10671213573142\n",
      "SGD iter. 38/49: loss=21.173423926584363, w0=76.24327499932295, w1=24.969496502937794\n",
      "SGD iter. 39/49: loss=28.88399456700254, w0=70.92290709139942, w1=27.097103971303973\n",
      "SGD iter. 40/49: loss=150.28143239490106, w0=83.05863136920843, w1=20.171804848002104\n",
      "SGD iter. 41/49: loss=40.32844310957729, w0=76.77198884339342, w1=26.489924758110696\n",
      "SGD iter. 42/49: loss=0.7825993521293972, w0=77.64774415458874, w1=26.735567358963838\n",
      "SGD iter. 43/49: loss=11244.94994324019, w0=182.624174577686, w1=-388.71610890045685\n",
      "SGD iter. 44/49: loss=18432.943420127314, w0=48.220735069149754, w1=-365.69629161224594\n",
      "SGD iter. 45/49: loss=191617.64181998963, w0=481.562735091753, w1=310.70384026156165\n",
      "SGD iter. 46/49: loss=411649.6775979776, w0=-153.5881792947556, w1=-749.3909829592837\n",
      "SGD iter. 47/49: loss=189801.77852570516, w0=277.6956517900545, w1=-537.1572898201932\n",
      "SGD iter. 48/49: loss=23998.967343415832, w0=431.054668468395, w1=-417.0126586086156\n",
      "SGD iter. 49/49: loss=332023.5374836803, w0=-139.36891689077186, w1=181.21037594815817\n",
      "GD: execution time=0.001 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: fit the model to the subsampled data / subsampled data with outliers and visualize the cloud of points\n",
    "#       and the model fit\n",
    "batch_size = 1\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "# ***************************************************\n",
    "#raise NotImplementedError\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1299d6ad7d2d4b62b77cd6aa8b0e4ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # TODO: compute subgradient gradient vector for MAE\n",
    "    e = y - tx @ w\n",
    "    gradient = - (1 / len(y) ) * (tx.T @ np.sign(e))\n",
    "    return gradient\n",
    "    # ***************************************************\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: compute subgradient and loss\n",
    "        gradient= compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        # ***************************************************\n",
    "        #raise NotImplementedError\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: update w by gradient\n",
    "        w = w - gamma * gradient\n",
    "        # ***************************************************\n",
    "        #raise NotImplementedError\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=2829.2722244384163, w0=51.54259072181176, w1=10.132993413506084\n",
      "SubGD iter. 1/499: loss=267.0500258779429, w0=67.0053679383553, w1=13.172891437557826\n",
      "SubGD iter. 2/499: loss=36.45002800750045, w0=71.64420110331838, w1=14.084860844773324\n",
      "SubGD iter. 3/499: loss=15.696028199160633, w0=73.03585105280729, w1=14.358451666937965\n",
      "SubGD iter. 4/499: loss=13.828168216410077, w0=73.45334603765397, w1=14.440528913587356\n",
      "SubGD iter. 5/499: loss=13.660060817962522, w0=73.57859453310797, w1=14.46515208758217\n",
      "SubGD iter. 6/499: loss=13.644931152102243, w0=73.61616908174418, w1=14.472539039780616\n",
      "SubGD iter. 7/499: loss=13.643569482174811, w0=73.62744144633503, w1=14.474755125440149\n",
      "SubGD iter. 8/499: loss=13.643446931881352, w0=73.63082315571229, w1=14.47541995113801\n",
      "SubGD iter. 9/499: loss=13.643435902354936, w0=73.63183766852546, w1=14.475619398847368\n",
      "SubGD iter. 10/499: loss=13.643434909697561, w0=73.63214202236942, w1=14.475679233160175\n",
      "SubGD iter. 11/499: loss=13.643434820358397, w0=73.6322333285226, w1=14.475697183454017\n",
      "SubGD iter. 12/499: loss=13.643434812317878, w0=73.63226072036856, w1=14.47570256854217\n",
      "SubGD iter. 13/499: loss=13.643434811594227, w0=73.63226893792235, w1=14.475704184068615\n",
      "SubGD iter. 14/499: loss=13.643434811529096, w0=73.63227140318848, w1=14.475704668726548\n",
      "SubGD iter. 15/499: loss=13.643434811523235, w0=73.63227214276833, w1=14.47570481412393\n",
      "SubGD iter. 16/499: loss=13.643434811522708, w0=73.63227236464228, w1=14.475704857743143\n",
      "SubGD iter. 17/499: loss=13.64343481152266, w0=73.63227243120447, w1=14.475704870828908\n",
      "SubGD iter. 18/499: loss=13.643434811522654, w0=73.63227245117312, w1=14.475704874754637\n",
      "SubGD iter. 19/499: loss=13.643434811522654, w0=73.63227245716372, w1=14.475704875932355\n",
      "SubGD iter. 20/499: loss=13.643434811522656, w0=73.6322724589609, w1=14.47570487628567\n",
      "SubGD iter. 21/499: loss=13.643434811522653, w0=73.63227245950004, w1=14.475704876391665\n",
      "SubGD iter. 22/499: loss=13.643434811522653, w0=73.63227245966179, w1=14.475704876423464\n",
      "SubGD iter. 23/499: loss=13.643434811522656, w0=73.63227245971032, w1=14.475704876433003\n",
      "SubGD iter. 24/499: loss=13.643434811522656, w0=73.63227245972487, w1=14.475704876435866\n",
      "SubGD iter. 25/499: loss=13.643434811522656, w0=73.63227245972924, w1=14.475704876436724\n",
      "SubGD iter. 26/499: loss=13.643434811522654, w0=73.63227245973054, w1=14.475704876436982\n",
      "SubGD iter. 27/499: loss=13.643434811522654, w0=73.63227245973094, w1=14.475704876437058\n",
      "SubGD iter. 28/499: loss=13.643434811522656, w0=73.63227245973106, w1=14.475704876437081\n",
      "SubGD iter. 29/499: loss=13.643434811522654, w0=73.6322724597311, w1=14.475704876437089\n",
      "SubGD iter. 30/499: loss=13.643434811522654, w0=73.63227245973111, w1=14.47570487643709\n",
      "SubGD iter. 31/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 32/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 33/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 34/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 35/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 36/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 37/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 38/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 39/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 40/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 41/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 42/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 43/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 44/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 45/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 46/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 47/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 48/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 49/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 50/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 51/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 52/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 53/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 54/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 55/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 56/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 57/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 58/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 59/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 60/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 61/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 62/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 63/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 64/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 65/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 66/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 67/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 68/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 69/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 70/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 71/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 72/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 73/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 74/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 75/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 76/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 77/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 78/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 79/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 80/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 81/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 82/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 83/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 84/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 85/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 86/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 87/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 88/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 89/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 90/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 91/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 92/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 93/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 94/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 95/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 96/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 97/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 98/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 99/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 100/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 101/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 102/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 103/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 104/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 105/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 106/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 107/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 108/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 109/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 110/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 111/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 112/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 113/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 114/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 115/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 116/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 117/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 118/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 119/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 120/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 121/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 122/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 123/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 124/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 125/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 126/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 127/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 128/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 129/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 130/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 131/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 132/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 133/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 134/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 135/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 136/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 137/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 138/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 139/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 140/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 141/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 142/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 143/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 144/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 145/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 146/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 147/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 148/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 149/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 150/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 151/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 152/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 153/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 154/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 155/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 156/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 157/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 158/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 159/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 160/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 161/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 162/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 163/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 164/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 165/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 166/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 167/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 168/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 169/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 170/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 171/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 172/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 173/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 174/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 175/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 176/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 177/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 178/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 179/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 180/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 181/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 182/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 183/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 184/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 185/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 186/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 187/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 188/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 189/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 190/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 191/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 192/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 193/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 194/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 195/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 196/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 197/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 198/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 199/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 200/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 201/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 202/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 203/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 204/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 205/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 206/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 207/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 208/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 209/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 210/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 211/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 212/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 213/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 214/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 215/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 216/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 217/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 218/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 219/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 220/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 221/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 222/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 223/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 224/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 225/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 226/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 227/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 228/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 229/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 230/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 231/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 232/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 233/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 234/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 235/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 236/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 237/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 238/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 239/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 240/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 241/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 242/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 243/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 244/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 245/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 246/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 247/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 248/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 249/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 250/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 251/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 252/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 253/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 254/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 255/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 256/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 257/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 258/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 259/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 260/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 261/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 262/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 263/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 264/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 265/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 266/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 267/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 268/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 269/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 270/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 271/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 272/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 273/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 274/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 275/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 276/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 277/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 278/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 279/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 280/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 281/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 282/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 283/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 284/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 285/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 286/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 287/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 288/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 289/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 290/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 291/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 292/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 293/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 294/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 295/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 296/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 297/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 298/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 299/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 300/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 301/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 302/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 303/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 304/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 305/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 306/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 307/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 308/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 309/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 310/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 311/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 312/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 313/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 314/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 315/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 316/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 317/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 318/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 319/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 320/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 321/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 322/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 323/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 324/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 325/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 326/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 327/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 328/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 329/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 330/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 331/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 332/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 333/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 334/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 335/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 336/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 337/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 338/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 339/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 340/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 341/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 342/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 343/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 344/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 345/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 346/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 347/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 348/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 349/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 350/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 351/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 352/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 353/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 354/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 355/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 356/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 357/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 358/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 359/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 360/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 361/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 362/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 363/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 364/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 365/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 366/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 367/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 368/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 369/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 370/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 371/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 372/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 373/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 374/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 375/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 376/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 377/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 378/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 379/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 380/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 381/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 382/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 383/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 384/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 385/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 386/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 387/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 388/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 389/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 390/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 391/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 392/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 393/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 394/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 395/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 396/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 397/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 398/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 399/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 400/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 401/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 402/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 403/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 404/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 405/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 406/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 407/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 408/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 409/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 410/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 411/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 412/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 413/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 414/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 415/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 416/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 417/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 418/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 419/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 420/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 421/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 422/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 423/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 424/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 425/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 426/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 427/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 428/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 429/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 430/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 431/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 432/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 433/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 434/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 435/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 436/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 437/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 438/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 439/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 440/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 441/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 442/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 443/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 444/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 445/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 446/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 447/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 448/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 449/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 450/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 451/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 452/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 453/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 454/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 455/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 456/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 457/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 458/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 459/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 460/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 461/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 462/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 463/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 464/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 465/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 466/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 467/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 468/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 469/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 470/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 471/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 472/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 473/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 474/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 475/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 476/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 477/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 478/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 479/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 480/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 481/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 482/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 483/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 484/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 485/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 486/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 487/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 488/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 489/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 490/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 491/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 492/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 493/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 494/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 495/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 496/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 497/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 498/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD iter. 499/499: loss=13.643434811522656, w0=73.63227245973111, w1=14.475704876437092\n",
      "SubGD: execution time=0.008 seconds\n"
     ]
    }
   ],
   "source": [
    "height, weight, gender = load_data(sub_sample=True, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994bad699c0d4e859df3138c8297df68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=1001, min=1), Output()), _dom_classes=('wid"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # TODO: implement stochastic gradient descent.\n",
    "        yB, txB = next(batch_iter(y, tx, batch_size, num_batches=1, shuffle=True))\n",
    "        gradient= compute_gradient(yB, txB, w)\n",
    "        loss = compute_loss(yB, txB, w)\n",
    "        w = w - gamma * gradient\n",
    "        # ***************************************************\n",
    "        #raise NotImplementedError\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/499: loss=1506.5271984306564, w0=38.42390732944846, w1=-35.83274815458299\n",
      "SGD iter. 1/499: loss=1734.9235714558054, w0=-2.8098785751551674, w1=45.28285533367088\n",
      "SGD iter. 2/499: loss=3340.53025731888, w0=54.406549591696546, w1=45.87820619071001\n",
      "SGD iter. 3/499: loss=1314.157268511639, w0=90.29351272793038, w1=8.834803119068745\n",
      "SGD iter. 4/499: loss=261.1725397643632, w0=74.29510377675415, w1=20.753531029091413\n",
      "SGD iter. 5/499: loss=6.554395357403213, w0=71.76067929568252, w1=21.85630941506512\n",
      "SGD iter. 6/499: loss=24.8401774945813, w0=76.69457977549459, w1=23.789558472105423\n",
      "SGD iter. 7/499: loss=8.653054302670311, w0=79.6066225664949, w1=21.915735976773323\n",
      "SGD iter. 8/499: loss=0.3338850598886057, w0=79.03460214842329, w1=22.700951782264777\n",
      "SGD iter. 9/499: loss=11.75878570154319, w0=75.63995783899817, w1=23.94536181772502\n",
      "SGD iter. 10/499: loss=0.4305590094807908, w0=74.99038272456477, w1=23.88588945614872\n",
      "SGD iter. 11/499: loss=290.24387311299904, w0=91.85570204116055, w1=-4.3640101980012105\n",
      "SGD iter. 12/499: loss=90.0025774928747, w0=82.46408205614108, w1=-7.629753575270574\n",
      "SGD iter. 13/499: loss=417.5888383737197, w0=62.23447351800458, w1=12.697947866094928\n",
      "SGD iter. 14/499: loss=144.66509147478874, w0=74.14126946172063, w1=4.003892134494492\n",
      "SGD iter. 15/499: loss=68.01217251829817, w0=82.30533273119204, w1=7.2028151127553315\n",
      "SGD iter. 16/499: loss=62.342800991331, w0=74.48894322122618, w1=20.295494543793584\n",
      "SGD iter. 17/499: loss=18.932810433722334, w0=70.18148988717276, w1=16.902732855297728\n",
      "SGD iter. 18/499: loss=5.708981757157613, w0=72.54682329327315, w1=17.546002453676977\n",
      "SGD iter. 19/499: loss=0.7064900370480218, w0=73.3789051620259, w1=16.754435023139816\n",
      "SGD iter. 20/499: loss=29.637146664725456, w0=78.76819117516632, w1=11.50505556512836\n",
      "SGD iter. 21/499: loss=0.5213881196986877, w0=79.4830060863879, w1=12.166122197489322\n",
      "SGD iter. 22/499: loss=60.52295370588088, w0=71.7815455345339, w1=22.525972434512283\n",
      "SGD iter. 23/499: loss=0.02190115605336284, w0=71.92804854792372, w1=22.528666044328503\n",
      "SGD iter. 24/499: loss=26.184119419486365, w0=76.99366174191087, w1=22.581374982182407\n",
      "SGD iter. 25/499: loss=0.2571601722663287, w0=76.49164882492467, w1=22.685522266901874\n",
      "SGD iter. 26/499: loss=6.670648379059732, w0=79.04845061847037, w1=21.040287955215934\n",
      "SGD iter. 27/499: loss=9.3887783288279, w0=76.01513514489177, w1=24.179684591467485\n",
      "SGD iter. 28/499: loss=106.30378108238882, w0=65.80838710936445, w1=14.473612929091182\n",
      "SGD iter. 29/499: loss=1.2419809179514427, w0=66.91162837925621, w1=15.56819481554124\n",
      "SGD iter. 30/499: loss=0.1769636984943139, w0=66.49518579675002, w1=15.773075868495383\n",
      "SGD iter. 31/499: loss=21.366708717269667, w0=71.07114193103762, w1=18.041375495927173\n",
      "SGD iter. 32/499: loss=15.432138616609073, w0=74.96003584117156, w1=13.806492410562845\n",
      "SGD iter. 33/499: loss=2.859887752799236, w0=73.2859121904984, w1=15.534563881760668\n",
      "SGD iter. 34/499: loss=1.9372485930594319, w0=71.9080502158441, w1=16.003461758608477\n",
      "SGD iter. 35/499: loss=43.686843775617774, w0=78.45122275675308, w1=17.71979298416238\n",
      "SGD iter. 36/499: loss=20.83147586290306, w0=73.93294362132497, w1=16.30006504159481\n",
      "SGD iter. 37/499: loss=72.63724783724238, w0=65.4958527198058, w1=4.057814173217059\n",
      "SGD iter. 38/499: loss=44.53154542930842, w0=72.10197976374934, w1=7.450848229203053\n",
      "SGD iter. 39/499: loss=178.79599249018375, w0=85.3390516695894, w1=39.092641687930104\n",
      "SGD iter. 40/499: loss=1918.5585870077846, w0=41.97792374067559, w1=-40.84332393155217\n",
      "SGD iter. 41/499: loss=1079.3789649166406, w0=74.50162872055616, w1=-36.562790458770266\n",
      "SGD iter. 42/499: loss=590.7119062252291, w0=98.56192107332537, w1=-21.442747417883453\n",
      "SGD iter. 43/499: loss=1056.4042656345819, w0=66.38621315070321, w1=-1.2310410118287827\n",
      "SGD iter. 44/499: loss=83.10932324546036, w0=57.3614064059274, w1=10.416907801962248\n",
      "SGD iter. 45/499: loss=285.9197597148491, w0=74.10062277111463, w1=26.64688503938519\n",
      "SGD iter. 46/499: loss=45.24132565036007, w0=67.44205692422591, w1=20.303249194834212\n",
      "SGD iter. 47/499: loss=8.430200877198528, w0=70.31635629270765, w1=18.592137526049527\n",
      "SGD iter. 48/499: loss=13.085910090076412, w0=66.73526820550917, w1=12.56956252471526\n",
      "SGD iter. 49/499: loss=8.62919547948739, w0=69.64329357848955, w1=10.814609502136118\n",
      "SGD iter. 50/499: loss=7.978329427176798, w0=66.84708850041797, w1=12.656841730056584\n",
      "SGD iter. 51/499: loss=110.09950886879467, w0=77.23446154134697, w1=5.865251517139065\n",
      "SGD iter. 52/499: loss=45.09450612661992, w0=83.88221424463607, w1=13.248146873120994\n",
      "SGD iter. 53/499: loss=40.56321590550449, w0=77.57729936912868, w1=21.251743433732482\n",
      "SGD iter. 54/499: loss=38.13275560358818, w0=71.46419046354583, w1=18.985614659264762\n",
      "SGD iter. 55/499: loss=0.6548736498270848, w0=70.66308112217567, w1=18.707045303794526\n",
      "SGD iter. 56/499: loss=13.615118459308702, w0=74.3158630880371, w1=18.390703096398852\n",
      "SGD iter. 57/499: loss=4.957362190094883, w0=76.51999896095714, w1=17.643043417476775\n",
      "SGD iter. 58/499: loss=23.861112948962624, w0=71.6843096936465, w1=12.325781918632362\n",
      "SGD iter. 59/499: loss=0.2371706678438139, w0=72.16641679221168, w1=13.108918878946126\n",
      "SGD iter. 60/499: loss=16.017907821826157, w0=68.2044034573793, w1=17.20949181456706\n",
      "SGD iter. 61/499: loss=20.561189246564595, w0=63.715532166995345, w1=17.02755158221911\n",
      "SGD iter. 62/499: loss=95.5841216932754, w0=73.39398448435529, w1=2.7364648064195745\n",
      "SGD iter. 63/499: loss=70.36004796944333, w0=65.090199382966, w1=13.277470861190087\n",
      "SGD iter. 64/499: loss=48.296945350008954, w0=71.96995275376418, w1=9.09535796552391\n",
      "SGD iter. 65/499: loss=39.052849702528306, w0=65.78353273015782, w1=12.138947410256577\n",
      "SGD iter. 66/499: loss=0.6657892551540087, w0=64.97577443088078, w1=12.536347623011874\n",
      "SGD iter. 67/499: loss=13.626804637927938, w0=68.63012369513692, w1=9.813877238501659\n",
      "SGD iter. 68/499: loss=21.338487625419095, w0=64.05719051468144, w1=12.002476182591124\n",
      "SGD iter. 69/499: loss=2.818247031588601, w0=65.71908163354477, w1=10.907567442715619\n",
      "SGD iter. 70/499: loss=1.1379453847856273, w0=66.77510553341159, w1=10.552035255689196\n",
      "SGD iter. 71/499: loss=351.2028599893621, w0=85.32716209837426, w1=46.0623832692133\n",
      "SGD iter. 72/499: loss=17.294960167224158, w0=81.21023837259554, w1=48.032736773971635\n",
      "SGD iter. 73/499: loss=1489.1099965448232, w0=43.00908921954091, w1=-11.376138432239685\n",
      "SGD iter. 74/499: loss=2889.394625083418, w0=96.2219329001952, w1=71.37831423947627\n",
      "SGD iter. 75/499: loss=2879.6313510155987, w0=43.099068481987416, w1=19.60085126634555\n",
      "SGD iter. 76/499: loss=756.6001775568124, w0=70.32898170266581, w1=-28.720989532049302\n",
      "SGD iter. 77/499: loss=2950.667341506858, w0=16.55488017900742, w1=77.0640748620302\n",
      "SGD iter. 78/499: loss=6915.6538837481385, w0=98.87948650101285, w1=-6.8373249873460935\n",
      "SGD iter. 79/499: loss=1111.261773383958, w0=65.87893290086427, w1=21.16227403496745\n",
      "SGD iter. 80/499: loss=215.0907670490421, w0=80.39750554792779, w1=8.334082086928746\n",
      "SGD iter. 81/499: loss=87.56696452061142, w0=71.1338332075328, w1=10.552677474469958\n",
      "SGD iter. 82/499: loss=10.062915272270411, w0=74.2741607329392, w1=12.109336574088289\n",
      "SGD iter. 83/499: loss=13.434168278812624, w0=77.90258806626646, w1=8.918049120830275\n",
      "SGD iter. 84/499: loss=38.45662210132979, w0=71.76357432957363, w1=11.168491171727377\n",
      "SGD iter. 85/499: loss=3.4354087049151203, w0=69.92871724227315, w1=13.16659279718469\n",
      "SGD iter. 86/499: loss=2.3055597043112006, w0=71.43186344614854, w1=11.226543493356667\n",
      "SGD iter. 87/499: loss=77.43653860992676, w0=80.14322429493262, w1=24.77409797838467\n",
      "SGD iter. 88/499: loss=173.01342616527654, w0=93.16448220812867, w1=-0.8414784387003991\n",
      "SGD iter. 89/499: loss=16.547061913813174, w0=89.13755773956251, w1=-4.56084959994674\n",
      "SGD iter. 90/499: loss=133.67118608710382, w0=100.58298312988164, w1=16.743139940432293\n",
      "SGD iter. 91/499: loss=415.8756717044939, w0=80.39491342843658, w1=33.871878552636474\n",
      "SGD iter. 92/499: loss=675.4761742627112, w0=54.66620085323265, w1=-1.759905045129031\n",
      "SGD iter. 93/499: loss=828.5546363213715, w0=83.16152579601834, w1=24.51750601692941\n",
      "SGD iter. 94/499: loss=89.83818077385828, w0=73.77848699409596, w1=29.211714252003254\n",
      "SGD iter. 95/499: loss=501.9632998513296, w0=51.599126456553336, w1=-3.3648358738976043\n",
      "SGD iter. 96/499: loss=52.0810805993789, w0=58.743317032636206, w1=-11.481959986770356\n",
      "SGD iter. 97/499: loss=87.66073179908172, w0=68.01194784646734, w1=-12.205585425986587\n",
      "SGD iter. 98/499: loss=216.96226735568658, w0=53.43034909980815, w1=0.16629545085084985\n",
      "SGD iter. 99/499: loss=91.36756457669865, w0=62.892918163501406, w1=-5.5858776249133735\n",
      "SGD iter. 100/499: loss=192.839302082144, w0=76.64000934820302, w1=-1.9760750166853764\n",
      "SGD iter. 101/499: loss=2.111013519879827, w0=78.07833936926295, w1=-1.5849107213696392\n",
      "SGD iter. 102/499: loss=518.0843302683141, w0=55.54563771892932, w1=41.7631674680797\n",
      "SGD iter. 103/499: loss=23.188707147340736, w0=60.312705266635554, w1=41.427412377139476\n",
      "SGD iter. 104/499: loss=309.51245733485297, w0=77.72885318137709, w1=28.670262811812428\n",
      "SGD iter. 105/499: loss=385.27354972997585, w0=58.29774207739294, w1=10.985110239379992\n",
      "SGD iter. 106/499: loss=3.2097762039398954, w0=60.07132057293834, w1=8.987117798367606\n",
      "SGD iter. 107/499: loss=224.57939016288884, w0=74.90667706881099, w1=40.283487498280664\n",
      "SGD iter. 108/499: loss=143.1182627942352, w0=63.06370879483717, w1=31.02806895431707\n",
      "SGD iter. 109/499: loss=119.90340941582622, w0=52.223720730844214, w1=16.015731754405834\n",
      "SGD iter. 110/499: loss=264.53216094052226, w0=68.32469951232554, w1=22.120870658451175\n",
      "SGD iter. 111/499: loss=408.292627694184, w0=88.32786863974883, w1=-21.745023583800403\n",
      "SGD iter. 112/499: loss=691.7883144102035, w0=114.36539056719037, w1=13.24529055553311\n",
      "SGD iter. 113/499: loss=565.4278949594498, w0=90.82565103888929, w1=-23.362756035435346\n",
      "SGD iter. 114/499: loss=496.1853339227418, w0=112.87699175196809, w1=4.667417263982191\n",
      "SGD iter. 115/499: loss=292.62874747665865, w0=95.94252475335472, w1=-17.472284259486702\n",
      "SGD iter. 116/499: loss=2266.704509230432, w0=48.811108277231035, w1=45.9279516910635\n",
      "SGD iter. 117/499: loss=33.94970340810545, w0=54.579185022554675, w1=49.105333416500066\n",
      "SGD iter. 118/499: loss=608.8867183920463, w0=79.00681249687574, w1=34.48944454951339\n",
      "SGD iter. 119/499: loss=25.24078697110963, w0=83.98033953829086, w1=30.893697987197264\n",
      "SGD iter. 120/499: loss=173.98507441300075, w0=70.92256894278947, w1=20.688897187551618\n",
      "SGD iter. 121/499: loss=0.05348857577214202, w0=70.69361741024011, w1=20.57540600434505\n",
      "SGD iter. 122/499: loss=8.318451913498468, w0=73.54880267134463, w1=17.940582925540124\n",
      "SGD iter. 123/499: loss=0.26828386108381413, w0=74.06155815289713, w1=17.90055080882281\n",
      "SGD iter. 124/499: loss=24.793660094701643, w0=78.9908366896414, w1=19.30923636339154\n",
      "SGD iter. 125/499: loss=0.5193481698148761, w0=78.27742151849729, w1=19.768300151991234\n",
      "SGD iter. 126/499: loss=22.644562935533063, w0=73.56661779972251, w1=22.87193317883618\n",
      "SGD iter. 127/499: loss=10.571983126379976, w0=70.34783798994172, w1=21.752668465884945\n",
      "SGD iter. 128/499: loss=79.39883703618285, w0=79.16888442987498, w1=26.135813857306793\n",
      "SGD iter. 129/499: loss=10.845871827775817, w0=75.90867670777807, w1=25.837322969718677\n",
      "SGD iter. 130/499: loss=104.64190281112911, w0=65.78202549649868, w1=25.42687563115638\n",
      "SGD iter. 131/499: loss=736.0718302077685, w0=92.63999253802311, w1=-33.471228679235594\n",
      "SGD iter. 132/499: loss=3352.9895745252506, w0=35.31696241020498, w1=31.10498330064962\n",
      "SGD iter. 133/499: loss=1272.0246616164213, w0=70.62396126856297, w1=9.642316359773641\n",
      "SGD iter. 134/499: loss=33.29283818025955, w0=76.33596454382939, w1=9.603014284811705\n",
      "SGD iter. 135/499: loss=82.17296948022192, w0=67.36214093899865, w1=17.8158935639115\n",
      "SGD iter. 136/499: loss=49.2920670430435, w0=74.31240896995851, w1=19.298973096343513\n",
      "SGD iter. 137/499: loss=21.664832744426104, w0=69.70463986880581, w1=15.005033590712152\n",
      "SGD iter. 138/499: loss=5.206775222977188, w0=71.96354219483004, w1=13.570513878492408\n",
      "SGD iter. 139/499: loss=14.752969496962343, w0=75.76589805758448, w1=10.0487618701347\n",
      "SGD iter. 140/499: loss=20.464490365389608, w0=71.28759474515891, w1=12.751355873333745\n",
      "SGD iter. 141/499: loss=25.092905241246232, w0=76.24653083432374, w1=13.809516016758185\n",
      "SGD iter. 142/499: loss=12.261750486032012, w0=72.78004623514961, w1=7.35716067615591\n",
      "SGD iter. 143/499: loss=67.37227225745458, w0=64.6544799895083, w1=11.422272287664201\n",
      "SGD iter. 144/499: loss=0.513932370398451, w0=65.36416564033583, w1=12.068190009310973\n",
      "SGD iter. 145/499: loss=66.28476538161728, w0=73.4238846226568, w1=7.382630726325446\n",
      "SGD iter. 146/499: loss=1.2179195320026694, w0=72.3313823840492, w1=7.626404636714645\n",
      "SGD iter. 147/499: loss=11.894218919146113, w0=75.7455198359927, w1=8.235312495280471\n",
      "SGD iter. 148/499: loss=16.594076583352656, w0=71.71287863552797, w1=12.763826941645807\n",
      "SGD iter. 149/499: loss=2.1294464496767724, w0=73.15747460696194, w1=14.373461316422382\n",
      "SGD iter. 150/499: loss=0.005990333642211931, w0=73.08085524276876, w1=14.349386076928239\n",
      "SGD iter. 151/499: loss=27.555004358969015, w0=78.2773833406231, w1=18.548602414006343\n",
      "SGD iter. 152/499: loss=0.31613892111592634, w0=77.72077203756359, w1=18.906767061879098\n",
      "SGD iter. 153/499: loss=11.069670357712296, w0=74.42709977843427, w1=18.011028970217836\n",
      "SGD iter. 154/499: loss=0.7841917727478335, w0=75.30374562328433, w1=16.800183102059158\n",
      "SGD iter. 155/499: loss=25.080060124724298, w0=80.26141230451955, w1=13.449958534984152\n",
      "SGD iter. 156/499: loss=54.314319164621786, w0=72.96565786914213, w1=20.390479424951856\n",
      "SGD iter. 157/499: loss=27.786302870121645, w0=67.74736535025062, w1=15.749210819518023\n",
      "SGD iter. 158/499: loss=126.72220317362964, w0=78.89132151985919, w1=-3.1040010132397207\n",
      "SGD iter. 159/499: loss=193.95992555881864, w0=65.1043448009537, w1=-2.132953807442481\n",
      "SGD iter. 160/499: loss=142.4372504305638, w0=76.91910275115956, w1=6.56612831867394\n",
      "SGD iter. 161/499: loss=46.585396961011504, w0=70.16235138517078, w1=10.643734154831057\n",
      "SGD iter. 162/499: loss=54.36467561895067, w0=62.86321567561094, w1=12.384751343492512\n",
      "SGD iter. 163/499: loss=75.31881990203678, w0=71.45463252639847, w1=19.174157784213033\n",
      "SGD iter. 164/499: loss=5.558703913361738, w0=69.1206381315692, w1=15.545311673890648\n",
      "SGD iter. 165/499: loss=5.502230186340234, w0=71.44274613564941, w1=13.815353803531101\n",
      "SGD iter. 166/499: loss=5.628514568747568, w0=73.79135088685227, w1=15.595042367293187\n",
      "SGD iter. 167/499: loss=8.254157069301826, w0=76.6354806180558, w1=11.984642007564073\n",
      "SGD iter. 168/499: loss=6.8757343477531645, w0=74.03967252407078, w1=7.767999551289521\n",
      "SGD iter. 169/499: loss=88.4232629805338, w0=83.34852840011285, w1=17.091680118603026\n",
      "SGD iter. 170/499: loss=106.69029212708692, w0=73.1232417887486, w1=-4.521775880245194\n",
      "SGD iter. 171/499: loss=123.78548669138466, w0=62.1091700186194, w1=2.0683217104623077\n",
      "SGD iter. 172/499: loss=9.492532567621527, w0=59.059140196426, w1=6.004870409414793\n",
      "SGD iter. 173/499: loss=0.017508445900261838, w0=59.19012980281619, w1=5.908921867383376\n",
      "SGD iter. 174/499: loss=175.44004166940476, w0=72.30238517083036, w1=12.408661614274003\n",
      "SGD iter. 175/499: loss=21.5387930570996, w0=67.70803895009801, w1=18.715347799673903\n",
      "SGD iter. 176/499: loss=7.814290884953627, w0=70.4753490279994, w1=21.4125723688483\n",
      "SGD iter. 177/499: loss=10.467920623602048, w0=67.27244999569601, w1=20.663691211007414\n",
      "SGD iter. 178/499: loss=1.9939367665505687, w0=65.87457373821842, w1=18.78533394702061\n",
      "SGD iter. 179/499: loss=8.677979723289896, w0=68.79080763295732, w1=18.27022322296639\n",
      "SGD iter. 180/499: loss=9.021658852350527, w0=71.76422749488458, w1=15.747399973765768\n",
      "SGD iter. 181/499: loss=1.828137966540622, w0=73.10272486403022, w1=16.484719754352298\n",
      "SGD iter. 182/499: loss=4.028184738012125, w0=71.11586275425715, w1=18.33759559508746\n",
      "SGD iter. 183/499: loss=9.90304899416763, w0=68.00057977926366, w1=19.896129808204396\n",
      "SGD iter. 184/499: loss=124.00433628762951, w0=79.024383549373, w1=15.15264913685883\n",
      "SGD iter. 185/499: loss=20.12056979873668, w0=74.58387024539992, w1=9.18583313599289\n",
      "SGD iter. 186/499: loss=1.0968701223138462, w0=75.6206598671977, w1=8.007848037548715\n",
      "SGD iter. 187/499: loss=6.771993147036513, w0=78.1968107331401, w1=11.471754822191722\n",
      "SGD iter. 188/499: loss=0.44662920571850084, w0=78.8583971761724, w1=11.928442307971382\n",
      "SGD iter. 189/499: loss=102.70840039491068, w0=68.82573888502083, w1=16.864300649474377\n",
      "SGD iter. 190/499: loss=67.51747829692307, w0=76.96005684850029, w1=9.330273941160993\n",
      "SGD iter. 191/499: loss=80.88237828530002, w0=68.05698261992093, w1=17.314241611246942\n",
      "SGD iter. 192/499: loss=47.23541553547269, w0=74.86071007072047, w1=24.128804245262998\n",
      "SGD iter. 193/499: loss=16.43115778393786, w0=70.84791371054231, w1=21.463045146924248\n",
      "SGD iter. 194/499: loss=23.32764877186556, w0=66.06658588279109, w1=16.91625802374533\n",
      "SGD iter. 195/499: loss=110.00081590293351, w0=76.4493022703688, w1=6.9889290545668\n",
      "SGD iter. 196/499: loss=80.53684326436138, w0=67.5652656653635, w1=24.46571356069886\n",
      "SGD iter. 197/499: loss=17.78395084239894, w0=63.390547492174925, w1=20.6718685628619\n",
      "SGD iter. 198/499: loss=41.525419177494605, w0=69.76980378064184, w1=16.208436792775036\n",
      "SGD iter. 199/499: loss=26.258998372793904, w0=74.84265489272249, w1=9.535800779993332\n",
      "SGD iter. 200/499: loss=38.92036029352675, w0=68.66673770677706, w1=12.599837721400155\n",
      "SGD iter. 201/499: loss=0.03005497736478984, w0=68.49511638578956, w1=12.836507460588054\n",
      "SGD iter. 202/499: loss=72.65713741655344, w0=76.93336233315459, w1=19.818987278429887\n",
      "SGD iter. 203/499: loss=0.5158752122207043, w0=77.6443881470153, w1=19.57780190586384\n",
      "SGD iter. 204/499: loss=43.7583380287988, w0=71.09586378894632, w1=22.79953912039826\n",
      "SGD iter. 205/499: loss=8.850825300889637, w0=74.04099685807441, w1=22.14238110322758\n",
      "SGD iter. 206/499: loss=67.38868227491282, w0=82.16755262478237, w1=9.603874338981424\n",
      "SGD iter. 207/499: loss=0.19218106571175853, w0=81.7335740027311, w1=9.202527386515351\n",
      "SGD iter. 208/499: loss=249.58966236787782, w0=66.09394903534393, w1=12.932949312604173\n",
      "SGD iter. 209/499: loss=120.33588568716749, w0=76.95346872883977, w1=5.534573610750243\n",
      "SGD iter. 210/499: loss=336.1425005915038, w0=95.1033902322423, w1=40.2751980125315\n",
      "SGD iter. 211/499: loss=39.45900736670463, w0=88.88488340026322, w1=44.62615676089494\n",
      "SGD iter. 212/499: loss=2200.1316530947424, w0=42.45074703451558, w1=-35.35439311401437\n",
      "SGD iter. 213/499: loss=8483.206947865798, w0=133.62937835188336, w1=130.72071881877753\n",
      "SGD iter. 214/499: loss=14211.12712030169, w0=15.617071460205096, w1=23.4750601633975\n",
      "SGD iter. 215/499: loss=3290.2864860305754, w0=72.40158304840108, w1=-72.59229773877816\n",
      "SGD iter. 216/499: loss=487.6776542717166, w0=94.26305832310022, w1=-64.4882513464316\n",
      "SGD iter. 217/499: loss=2646.5873570772387, w0=43.33511304807766, w1=-34.01631177120285\n",
      "SGD iter. 218/499: loss=2489.8143687311795, w0=92.73165221183442, w1=9.918098882826072\n",
      "SGD iter. 219/499: loss=181.95980878897876, w0=79.37797808771415, w1=10.960653980478385\n",
      "SGD iter. 220/499: loss=19.642118944584553, w0=74.99057833778335, w1=9.435025633119304\n",
      "SGD iter. 221/499: loss=42.789491054331386, w0=68.51495472045931, w1=13.309613749985651\n",
      "SGD iter. 222/499: loss=2.0831903532608504, w0=69.9437747042906, w1=13.998679840966407\n",
      "SGD iter. 223/499: loss=0.5525667817711712, w0=70.6796520351928, w1=13.728921641882074\n",
      "SGD iter. 224/499: loss=11.525350014584879, w0=74.04043215508955, w1=12.889385132582706\n",
      "SGD iter. 225/499: loss=20.9017723800826, w0=78.56632841246012, w1=16.634473800518972\n",
      "SGD iter. 226/499: loss=35.037120218829195, w0=84.42605347550298, w1=6.819264143090372\n",
      "SGD iter. 227/499: loss=46.283443067886, w0=77.6912354225391, w1=12.742695530288751\n",
      "SGD iter. 228/499: loss=20.97129515455009, w0=73.1578184715562, w1=19.436684704691146\n",
      "SGD iter. 229/499: loss=19.42875207973877, w0=68.79431333942401, w1=13.573346288618506\n",
      "SGD iter. 230/499: loss=29.696925121568746, w0=74.18903173977981, w1=13.033839668639946\n",
      "SGD iter. 231/499: loss=15.681107745794185, w0=70.26889327400104, w1=15.85219917083277\n",
      "SGD iter. 232/499: loss=7.219142023204895, w0=72.92873522094843, w1=16.421257209666773\n",
      "SGD iter. 233/499: loss=50.720269549548405, w0=79.9789738097167, w1=12.170991020417324\n",
      "SGD iter. 234/499: loss=38.2402011008676, w0=86.10068901698095, w1=22.78146710608014\n",
      "SGD iter. 235/499: loss=27.26637865694176, w0=80.93144815551948, w1=27.699015318815725\n",
      "SGD iter. 236/499: loss=1.6351667939354924, w0=82.19733261235461, w1=26.580980653484\n",
      "SGD iter. 237/499: loss=328.2257367518273, w0=64.26241633106713, w1=7.544123153037916\n",
      "SGD iter. 238/499: loss=122.64890458288589, w0=75.22580661378662, w1=22.285558712988678\n",
      "SGD iter. 239/499: loss=70.2866235883403, w0=66.92635535984377, w1=12.681976184659636\n",
      "SGD iter. 240/499: loss=22.132264512122575, w0=71.58356688841751, w1=14.145359287690844\n",
      "SGD iter. 241/499: loss=0.033023161724782986, w0=71.76346324327298, w1=14.03679432995768\n",
      "SGD iter. 242/499: loss=8.566188210683553, w0=68.86607399664597, w1=13.359345496308576\n",
      "SGD iter. 243/499: loss=166.6018865670531, w0=81.64378305718229, w1=19.708541928159892\n",
      "SGD iter. 244/499: loss=194.9640366124873, w0=67.8211655091114, w1=23.005564438916323\n",
      "SGD iter. 245/499: loss=17.16600883811439, w0=71.92271261494257, w1=20.303329784544278\n",
      "SGD iter. 246/499: loss=24.044391444443605, w0=76.77693795124028, w1=20.269929746264292\n",
      "SGD iter. 247/499: loss=36.04326934780619, w0=70.83367252213063, w1=12.499852147364168\n",
      "SGD iter. 248/499: loss=0.19207287825675515, w0=70.3998160704192, w1=12.813520461980612\n",
      "SGD iter. 249/499: loss=13.37991129314084, w0=74.02090887056643, w1=11.585218199144874\n",
      "SGD iter. 250/499: loss=41.327674262241324, w0=67.65685978393955, w1=18.171830923579165\n",
      "SGD iter. 251/499: loss=43.585909972732686, w0=74.19246930205476, w1=24.198745801491267\n",
      "SGD iter. 252/499: loss=3.100132836831572, w0=72.44944601474764, w1=24.78557047605824\n",
      "SGD iter. 253/499: loss=11.10381775671655, w0=75.7481944746309, w1=23.554977943517546\n",
      "SGD iter. 254/499: loss=4.651470572255114, w0=73.61314385209054, w1=22.814866129616956\n",
      "SGD iter. 255/499: loss=33.7163524087913, w0=79.36136317294248, w1=16.55523618460726\n",
      "SGD iter. 256/499: loss=3.1673570950844314, w0=77.59954310460895, w1=19.15671859670097\n",
      "SGD iter. 257/499: loss=34.748391483650806, w0=83.43507424187297, w1=15.341265353339537\n",
      "SGD iter. 258/499: loss=106.48084354419639, w0=73.21982942477179, w1=17.78775678795116\n",
      "SGD iter. 259/499: loss=36.23118464398883, w0=79.17856762602791, w1=12.090369692233587\n",
      "SGD iter. 260/499: loss=7.255241771355794, w0=76.51208362346411, w1=9.983168519772095\n",
      "SGD iter. 261/499: loss=0.13647517323134117, w0=76.87779617420131, w1=10.272174534792763\n",
      "SGD iter. 262/499: loss=0.17848400549148216, w0=76.45956857422534, w1=10.972717910825423\n",
      "SGD iter. 263/499: loss=5.905616570646841, w0=78.86529180004204, w1=11.438211915423272\n",
      "SGD iter. 264/499: loss=7.921848701766677, w0=76.07900184245842, w1=9.593949358029205\n",
      "SGD iter. 265/499: loss=108.88248692594895, w0=86.40880518944573, w1=28.408919733306924\n",
      "SGD iter. 266/499: loss=35.48271598413889, w0=80.51193638774629, w1=28.998644630801493\n",
      "SGD iter. 267/499: loss=213.44485892502456, w0=66.04901960908356, w1=15.640322170579735\n",
      "SGD iter. 268/499: loss=48.4320070031669, w0=72.93838582544218, w1=11.312652127586492\n",
      "SGD iter. 269/499: loss=39.35909719033894, w0=79.149015040468, w1=16.451823635565372\n",
      "SGD iter. 270/499: loss=17.502687765723227, w0=75.00744118377912, w1=18.951206077535538\n",
      "SGD iter. 271/499: loss=5.772644630918477, w0=72.62895600654969, w1=18.20384148011222\n",
      "SGD iter. 272/499: loss=2.6648035547667384, w0=71.01294007727442, w1=19.005590006868623\n",
      "SGD iter. 273/499: loss=51.51074979805957, w0=78.11790558050512, w1=5.990583037620068\n",
      "SGD iter. 274/499: loss=62.70475082587574, w0=70.27885871182535, w1=10.721339214698983\n",
      "SGD iter. 275/499: loss=1.339663451366266, w0=69.13305323865858, w1=11.424409951992628\n",
      "SGD iter. 276/499: loss=23.215654833790293, w0=73.90288989593674, w1=19.183991793276274\n",
      "SGD iter. 277/499: loss=95.84487517476887, w0=83.59453463103065, w1=0.11847078340145245\n",
      "SGD iter. 278/499: loss=5.34535282282255, w0=81.30576951281382, w1=-1.5667229221887542\n",
      "SGD iter. 279/499: loss=92.94723950754246, w0=90.8497883056176, w1=13.9366245473222\n",
      "SGD iter. 280/499: loss=230.86957512594196, w0=75.80810676320276, w1=26.698866566409237\n",
      "SGD iter. 281/499: loss=187.92814040633925, w0=62.237197523280315, w1=5.599098153112418\n",
      "SGD iter. 282/499: loss=105.67923176284941, w0=72.41391836683265, w1=20.546438772609548\n",
      "SGD iter. 283/499: loss=8.147891181082782, w0=75.23968080508911, w1=18.7519335950158\n",
      "SGD iter. 284/499: loss=6.3633870023351315, w0=72.7424584957445, w1=17.967259566450334\n",
      "SGD iter. 285/499: loss=2.1395485018070994, w0=71.29444001113494, w1=17.463740814220127\n",
      "SGD iter. 286/499: loss=5.1155508171287085, w0=73.53346654085408, w1=16.041843259792344\n",
      "SGD iter. 287/499: loss=57.60823595469375, w0=81.04719206389522, w1=6.878480736475449\n",
      "SGD iter. 288/499: loss=20.713122812439885, w0=85.55261772149863, w1=9.142175328438876\n",
      "SGD iter. 289/499: loss=47.04253896001745, w0=78.76279532464486, w1=17.42270193278645\n",
      "SGD iter. 290/499: loss=62.19562725627072, w0=70.95563740955531, w1=23.14136496266473\n",
      "SGD iter. 291/499: loss=77.56727445609818, w0=62.23692598142694, w1=11.066791159160974\n",
      "SGD iter. 292/499: loss=184.25160125414192, w0=75.67443204576266, w1=-2.7630757160672914\n",
      "SGD iter. 293/499: loss=58.00497310990017, w0=83.21398598798643, w1=0.04017769298326268\n",
      "SGD iter. 294/499: loss=0.7227439985355877, w0=82.37238684435279, w1=-0.12266703970752649\n",
      "SGD iter. 295/499: loss=11.373652067008388, w0=79.03379746773454, w1=-1.1717143616355594\n",
      "SGD iter. 296/499: loss=98.1817740166473, w0=88.84288195795656, w1=6.754821792403028\n",
      "SGD iter. 297/499: loss=230.31746272104965, w0=73.81919687517383, w1=15.821407590203306\n",
      "SGD iter. 298/499: loss=78.2201850829201, w0=82.57452561721783, w1=6.8104326093102205\n",
      "SGD iter. 299/499: loss=252.21795032920235, w0=66.85277026602952, w1=29.7062702975608\n",
      "SGD iter. 300/499: loss=547.1139599313587, w0=90.0081515138676, w1=-11.384960409501048\n",
      "SGD iter. 301/499: loss=516.6890214279138, w0=67.50581294652409, w1=8.497456783901299\n",
      "SGD iter. 302/499: loss=10.893982268164459, w0=64.23838236228804, w1=10.104964389209401\n",
      "SGD iter. 303/499: loss=25.539605286285166, w0=69.24126285062268, w1=5.077825049267062\n",
      "SGD iter. 304/499: loss=52.997408136575686, w0=62.034497974907346, w1=14.772220586731034\n",
      "SGD iter. 305/499: loss=167.22848174996452, w0=74.8362131769795, w1=27.5943229854837\n",
      "SGD iter. 306/499: loss=8.00577172283724, w0=72.03520330759659, w1=26.53224132223395\n",
      "SGD iter. 307/499: loss=10.437639743641137, w0=75.23346642197106, w1=24.2944837297691\n",
      "SGD iter. 308/499: loss=10.598901585502933, w0=72.0105913772644, w1=22.269154665729033\n",
      "SGD iter. 309/499: loss=29.954357639335818, w0=77.42864180952776, w1=24.99138612499225\n",
      "SGD iter. 310/499: loss=0.21265762297903787, w0=76.97212842470815, w1=25.08609410532169\n",
      "SGD iter. 311/499: loss=257.4854211704014, w0=61.08705011999106, w1=-1.6289916905904747\n",
      "SGD iter. 312/499: loss=30.63935884810346, w0=66.56670080877966, w1=-4.81461493734265\n",
      "SGD iter. 313/499: loss=43.739893115019875, w0=60.019556755627974, w1=-0.8972336862321226\n",
      "SGD iter. 314/499: loss=59.431781870025944, w0=67.6512764984268, w1=-3.485971160462793\n",
      "SGD iter. 315/499: loss=18.322786434964684, w0=63.41378541215117, w1=0.4388042372503751\n",
      "SGD iter. 316/499: loss=31.692122999673472, w0=68.98678106437269, w1=-1.4515983423573948\n",
      "SGD iter. 317/499: loss=79.17537005624415, w0=77.79540539823546, w1=2.91483322043078\n",
      "SGD iter. 318/499: loss=2.87349415936492, w0=79.47350678855061, w1=3.5511325548991284\n",
      "SGD iter. 319/499: loss=0.4096927756836929, w0=80.10714621296327, w1=4.470545760742109\n",
      "SGD iter. 320/499: loss=0.0019342925443043225, w0=80.06360764737576, w1=4.424332137223381\n",
      "SGD iter. 321/499: loss=58.60806915902198, w0=87.64225579700255, w1=20.412095854412712\n",
      "SGD iter. 322/499: loss=381.2289041186925, w0=68.31340880510159, w1=-25.791429265310825\n",
      "SGD iter. 323/499: loss=761.281666392691, w0=95.62743511146728, w1=1.3082081910555203\n",
      "SGD iter. 324/499: loss=672.4182030014945, w0=69.95702726621744, w1=19.269253922157656\n",
      "SGD iter. 325/499: loss=50.61276261043932, w0=76.99979003080283, w1=16.077598126951283\n",
      "SGD iter. 326/499: loss=62.463998024639984, w0=69.17580651445087, w1=1.6541339035155946\n",
      "SGD iter. 327/499: loss=197.5154605695821, w0=83.08857587781597, w1=14.715273555027512\n",
      "SGD iter. 328/499: loss=122.03715472826894, w0=72.15256144687709, w1=12.158285318243662\n",
      "SGD iter. 329/499: loss=0.4361566896183493, w0=72.80634547530389, w1=12.425194930551282\n",
      "SGD iter. 330/499: loss=0.422818135575211, w0=72.16263608989483, w1=12.449956951789476\n",
      "SGD iter. 331/499: loss=25.49506005240217, w0=77.16115175470514, w1=17.296408164971226\n",
      "SGD iter. 332/499: loss=14.80069123003495, w0=80.96965243153772, w1=14.515532663724784\n",
      "SGD iter. 333/499: loss=48.743072268417166, w0=74.05819738769574, w1=20.619759858532273\n",
      "SGD iter. 334/499: loss=1.9003252276319176, w0=72.69352939764129, w1=21.518848187712905\n",
      "SGD iter. 335/499: loss=261.905610852439, w0=88.71437515045315, w1=-13.614021058531286\n",
      "SGD iter. 336/499: loss=1083.8889176761788, w0=56.12279434616176, w1=21.877184786326666\n",
      "SGD iter. 337/499: loss=52.023558715690235, w0=63.263038567571584, w1=30.52177049076382\n",
      "SGD iter. 338/499: loss=14.171415126251633, w0=59.53637963177848, w1=27.777870677063024\n",
      "SGD iter. 339/499: loss=0.1584809514947466, w0=59.14228404379905, w1=27.24826849515214\n",
      "SGD iter. 340/499: loss=6.391704009710969, w0=56.63951159518996, w1=23.357009764935075\n",
      "SGD iter. 341/499: loss=157.40695571765707, w0=69.0596088815764, w1=14.666928302641372\n",
      "SGD iter. 342/499: loss=0.24733239855542774, w0=69.55193575529377, w1=14.312972916922467\n",
      "SGD iter. 343/499: loss=67.61860074117799, w0=77.69234291503427, w1=15.384354094156066\n",
      "SGD iter. 344/499: loss=15.66234175805061, w0=73.77455081706766, w1=11.076400474427242\n",
      "SGD iter. 345/499: loss=0.5230088178197742, w0=73.05862579203824, w1=10.961196137495445\n",
      "SGD iter. 346/499: loss=3.4557266176483616, w0=74.89890079466568, w1=12.410687064269009\n",
      "SGD iter. 347/499: loss=1.8973533257997646, w0=76.26250127108234, w1=11.08248583086199\n",
      "SGD iter. 348/499: loss=13.417578475607838, w0=79.88868754678519, w1=18.74725069196881\n",
      "SGD iter. 349/499: loss=4.469151932315346, w0=77.79589780730608, w1=21.63325575805097\n",
      "SGD iter. 350/499: loss=40.30733376643612, w0=71.5109008231296, w1=15.507434001291596\n",
      "SGD iter. 351/499: loss=50.01629499770523, w0=78.51204138004968, w1=10.776298449134055\n",
      "SGD iter. 352/499: loss=0.6276122011478977, w0=79.29629896345257, w1=11.548033853618447\n",
      "SGD iter. 353/499: loss=1.56982280943823, w0=78.05596580125402, w1=9.881370733391064\n",
      "SGD iter. 354/499: loss=16.719090524185976, w0=74.00816285228254, w1=12.424065520120301\n",
      "SGD iter. 355/499: loss=1.5419432918758522, w0=72.77889297709713, w1=14.030368112893372\n",
      "SGD iter. 356/499: loss=3.6374617605113073, w0=70.89084834698346, w1=12.640220691816008\n",
      "SGD iter. 357/499: loss=58.183168371280324, w0=78.44197442220262, w1=24.383425192594544\n",
      "SGD iter. 358/499: loss=0.06604988293666947, w0=78.69639314257897, w1=24.19948626322626\n",
      "SGD iter. 359/499: loss=8.030694652893661, w0=75.89102672090857, w1=23.94263872939007\n",
      "SGD iter. 360/499: loss=11.297341791823746, w0=72.56365614401346, w1=20.60996919393282\n",
      "SGD iter. 361/499: loss=159.05999629254737, w0=60.07851311853328, w1=2.2720695547550456\n",
      "SGD iter. 362/499: loss=0.31072667947830945, w0=60.63033931027189, w1=1.338496600108587\n",
      "SGD iter. 363/499: loss=58.64381659684112, w0=68.21129836997564, w1=1.0468745211125192\n",
      "SGD iter. 364/499: loss=229.19363710364837, w0=83.19828487032237, w1=15.116476231882706\n",
      "SGD iter. 365/499: loss=55.2306783279177, w0=75.84124302176943, w1=-2.4697392314041036\n",
      "SGD iter. 366/499: loss=307.0379666257941, w0=93.1876319051445, w1=26.702938320396946\n",
      "SGD iter. 367/499: loss=339.0147252413487, w0=74.96033285299413, w1=19.261579841311416\n",
      "SGD iter. 368/499: loss=22.254355035782574, w0=79.63037224630409, w1=10.706915469900057\n",
      "SGD iter. 369/499: loss=0.002796228313253675, w0=79.57802433567731, w1=10.738473629501815\n",
      "SGD iter. 370/499: loss=9.422451579441077, w0=76.53927417354613, w1=9.912063453529338\n",
      "SGD iter. 371/499: loss=48.77705002981232, w0=69.62541063503049, w1=7.393691844466985\n",
      "SGD iter. 372/499: loss=37.073797111141566, w0=63.597780821503555, w1=15.719209723066491\n",
      "SGD iter. 373/499: loss=116.57350843141803, w0=74.28618754387287, w1=-1.3355250180021017\n",
      "SGD iter. 374/499: loss=664.5528839778889, w0=99.80601956327165, w1=45.14695555768955\n",
      "SGD iter. 375/499: loss=4495.738505597478, w0=33.429640214247726, w1=-94.87931937723792\n",
      "SGD iter. 376/499: loss=11275.72349661118, w0=138.54961465621074, w1=8.562212731839239\n",
      "SGD iter. 377/499: loss=2091.3837166575786, w0=93.27759192335256, w1=13.251878403769044\n",
      "SGD iter. 378/499: loss=63.84938504808469, w0=85.3673202878698, w1=11.17694516217883\n",
      "SGD iter. 379/499: loss=14.41987550890223, w0=81.60813447193516, w1=12.794501645380409\n",
      "SGD iter. 380/499: loss=105.56046135868468, w0=71.43713392471706, w1=18.849444255187002\n",
      "SGD iter. 381/499: loss=0.5106025685686072, w0=72.1445167893648, w1=18.117322784419862\n",
      "SGD iter. 382/499: loss=14.125417418427762, w0=75.8651227978074, w1=21.123874320422175\n",
      "SGD iter. 383/499: loss=0.5656872088482612, w0=75.1205601982422, w1=20.991082356287464\n",
      "SGD iter. 384/499: loss=203.15047618294471, w0=61.010724385615404, w1=-4.430193141372669\n",
      "SGD iter. 385/499: loss=2.5823979924646894, w0=62.6015575109354, w1=-5.429501444000183\n",
      "SGD iter. 386/499: loss=0.0014608895747206918, w0=62.63939494984485, w1=-5.453269660949254\n",
      "SGD iter. 387/499: loss=4.86665999084356, w0=64.82327379058366, w1=-5.839020410547606\n",
      "SGD iter. 388/499: loss=650.3237291546567, w0=90.06841697836461, w1=28.083437198627102\n",
      "SGD iter. 389/499: loss=333.5618022358199, w0=71.98830176326979, w1=11.11004365114276\n",
      "SGD iter. 390/499: loss=16.793290922591442, w0=76.045076973229, w1=17.932616112532976\n",
      "SGD iter. 391/499: loss=17.82277961036501, w0=71.8658038285114, w1=16.383360034180523\n",
      "SGD iter. 392/499: loss=0.0005125826893974335, w0=71.8882165712175, w1=16.386966620166497\n",
      "SGD iter. 393/499: loss=72.87245444367674, w0=80.33895650064399, w1=10.629644867345124\n",
      "SGD iter. 394/499: loss=94.89398227817836, w0=70.69550781085387, w1=15.414016506155372\n",
      "SGD iter. 395/499: loss=53.4647247312979, w0=77.93397658792765, w1=16.366691114141094\n",
      "SGD iter. 396/499: loss=6.507942041176916, w0=80.45940391817363, w1=17.08840585854268\n",
      "SGD iter. 397/499: loss=198.96329512531278, w0=66.49573573166883, w1=4.379425861072331\n",
      "SGD iter. 398/499: loss=46.50922024271491, w0=59.74451096590517, w1=13.704391764530927\n",
      "SGD iter. 399/499: loss=161.89280937013461, w0=72.34034175163471, w1=25.52920540317482\n",
      "SGD iter. 400/499: loss=5.420415796703274, w0=74.64512102105927, w1=25.2904565342547\n",
      "SGD iter. 401/499: loss=43.199658893058725, w0=68.13853468756629, w1=18.887760351065566\n",
      "SGD iter. 402/499: loss=24.756246276155697, w0=73.0640926610991, w1=19.338723693499738\n",
      "SGD iter. 403/499: loss=21.07156186034328, w0=77.60833414050316, w1=22.283723724310292\n",
      "SGD iter. 404/499: loss=19.436631622675527, w0=81.97272401655938, w1=16.650784281129628\n",
      "SGD iter. 405/499: loss=49.29331853992337, w0=75.02236775453045, w1=5.844514419173345\n",
      "SGD iter. 406/499: loss=128.5513982129244, w0=63.798270006886504, w1=17.461141512807234\n",
      "SGD iter. 407/499: loss=62.82354868476091, w0=71.64473913070682, w1=22.877492307393098\n",
      "SGD iter. 408/499: loss=0.00780122914313199, w0=71.55730227028589, w1=22.822544966207847\n",
      "SGD iter. 409/499: loss=12.51213626262087, w0=75.05900093484405, w1=19.198384833694146\n",
      "SGD iter. 410/499: loss=6.897652611366586, w0=72.45905871257463, w1=16.639955683627036\n",
      "SGD iter. 411/499: loss=0.12290423362349684, w0=72.11200518795484, w1=16.76717870009437\n",
      "SGD iter. 412/499: loss=51.039661064927486, w0=79.18440703199826, w1=11.60308114781892\n",
      "SGD iter. 413/499: loss=50.01373063805834, w0=72.18344595331077, w1=15.898898354690022\n",
      "SGD iter. 414/499: loss=8.11295269854357, w0=69.3637485148304, w1=16.707954637753314\n",
      "SGD iter. 415/499: loss=4.4923166603500615, w0=67.26554205998782, w1=16.894091774667697\n",
      "SGD iter. 416/499: loss=23.56926634392988, w0=72.0715675506663, w1=13.842017223067579\n",
      "SGD iter. 417/499: loss=6.356200866058655, w0=74.56737941231323, w1=14.070523245179807\n",
      "SGD iter. 418/499: loss=24.962397814056416, w0=69.6213557712683, w1=19.1895193129374\n",
      "SGD iter. 419/499: loss=14.718023969101097, w0=65.82350592040281, w1=12.802400366489689\n",
      "SGD iter. 420/499: loss=3.377234541819743, w0=67.64276122161354, w1=11.494457927761736\n",
      "SGD iter. 421/499: loss=77.10127285891761, w0=76.33524345638051, w1=25.00934914453682\n",
      "SGD iter. 422/499: loss=5.693558728309797, w0=78.6973796831345, w1=24.208094541967604\n",
      "SGD iter. 423/499: loss=59.94043249131914, w0=71.03307124456728, w1=21.366936277443447\n",
      "SGD iter. 424/499: loss=38.19658158057605, w0=64.91484846757031, w1=22.82627769027136\n",
      "SGD iter. 425/499: loss=22.02598167613021, w0=69.56086418456994, w1=25.745941199745964\n",
      "SGD iter. 426/499: loss=49.83078782817202, w0=76.54900929408281, w1=19.297138642723993\n",
      "SGD iter. 427/499: loss=54.83037231376499, w0=69.21867745524429, w1=12.326384991403021\n",
      "SGD iter. 428/499: loss=54.23162982404569, w0=76.50887616498909, w1=4.043368587472068\n",
      "SGD iter. 429/499: loss=60.30081824705099, w0=84.19619051280328, w1=13.81496280389674\n",
      "SGD iter. 430/499: loss=0.5623558258920706, w0=83.45382354871192, w1=13.333854847369633\n",
      "SGD iter. 431/499: loss=22.91532482899921, w0=78.71493988982988, w1=3.317152398063673\n",
      "SGD iter. 432/499: loss=345.59305823993867, w0=60.311646785737345, w1=37.02864443809909\n",
      "SGD iter. 433/499: loss=351.34059090178783, w0=78.8673407658544, w1=21.182541958766336\n",
      "SGD iter. 434/499: loss=272.14154095936, w0=62.53642804977595, w1=-13.268823065161122\n",
      "SGD iter. 435/499: loss=2.417255609477879, w0=64.07555458690288, w1=-14.27515225780731\n",
      "SGD iter. 436/499: loss=27.632557898350395, w0=69.27939035875266, w1=-14.814210345085831\n",
      "SGD iter. 437/499: loss=189.32895471679393, w0=55.65799631766942, w1=-4.666345652644713\n",
      "SGD iter. 438/499: loss=2.3007526853808815, w0=57.15957469779923, w1=-5.751952557651851\n",
      "SGD iter. 439/499: loss=535.8843414894944, w0=80.07608958684168, w1=16.04042783527393\n",
      "SGD iter. 440/499: loss=173.66350982467952, w0=67.03039145955903, w1=-3.120802636246257\n",
      "SGD iter. 441/499: loss=322.91376801779046, w0=84.81958741264906, w1=16.43996760930972\n",
      "SGD iter. 442/499: loss=165.01957748890942, w0=72.10270155410919, w1=-4.770731660090874\n",
      "SGD iter. 443/499: loss=173.2301572011305, w0=59.07329043705912, w1=6.2841824845201355\n",
      "SGD iter. 444/499: loss=10.871406180949636, w0=62.33733364408482, w1=3.9375186438434424\n",
      "SGD iter. 445/499: loss=230.27378222061432, w0=77.3595940124915, w1=20.9545952491904\n",
      "SGD iter. 446/499: loss=30.685344985194785, w0=82.84335532070787, w1=17.24885360982217\n",
      "SGD iter. 447/499: loss=147.70722313623662, w0=70.8120179605674, w1=23.007033579502988\n",
      "SGD iter. 448/499: loss=8.135186910508041, w0=73.6355765613933, w1=20.595784558419147\n",
      "SGD iter. 449/499: loss=2.9024479776414815, w0=75.32211117950484, w1=20.44972544814953\n",
      "SGD iter. 450/499: loss=38.68859983136982, w0=69.16460942678545, w1=13.679016002418193\n",
      "SGD iter. 451/499: loss=34.705818612332116, w0=74.99656469411093, w1=8.277443683388192\n",
      "SGD iter. 452/499: loss=7.32005773039785, w0=77.67493296150619, w1=6.526242524081063\n",
      "SGD iter. 453/499: loss=162.84286409632156, w0=65.04219743770157, w1=15.779591616275388\n",
      "SGD iter. 454/499: loss=8.332010324838302, w0=62.184686262160604, w1=16.461175884792713\n",
      "SGD iter. 455/499: loss=0.5640001808108197, w0=61.44123473233865, w1=16.63850672831456\n",
      "SGD iter. 456/499: loss=137.17460804912682, w0=73.03567805179752, w1=37.756924983302795\n",
      "SGD iter. 457/499: loss=214.77165186471456, w0=58.52787949972835, w1=21.96188311167326\n",
      "SGD iter. 458/499: loss=153.5460467100854, w0=70.79470980653066, w1=10.64180240221934\n",
      "SGD iter. 459/499: loss=8.166589007578297, w0=73.62371267457918, w1=9.68218307839215\n",
      "SGD iter. 460/499: loss=42.38303551084334, w0=67.17891827905139, w1=12.213206765135254\n",
      "SGD iter. 461/499: loss=33.13009554200922, w0=72.8769436941552, w1=11.719740154081858\n",
      "SGD iter. 462/499: loss=35.73161397574293, w0=66.9594288698199, w1=14.631033857010364\n",
      "SGD iter. 463/499: loss=1.1579984335417077, w0=68.0247168425629, w1=14.272382729123933\n",
      "SGD iter. 464/499: loss=88.91593503948681, w0=77.35946999080934, w1=6.062247079544207\n",
      "SGD iter. 465/499: loss=59.32422609031771, w0=69.73465907062835, w1=14.844874296498523\n",
      "SGD iter. 466/499: loss=18.828706680990937, w0=74.03025362172033, w1=12.233638050308649\n",
      "SGD iter. 467/499: loss=20.773698717621823, w0=78.54226256932553, w1=9.513554349006883\n",
      "SGD iter. 468/499: loss=48.61307429972258, w0=71.64003011788432, w1=7.8997189524521145\n",
      "SGD iter. 469/499: loss=10.489892979807276, w0=68.43377137595299, w1=8.66759918339401\n",
      "SGD iter. 470/499: loss=55.44409369029625, w0=75.80501359260076, w1=1.081124574696541\n",
      "SGD iter. 471/499: loss=24.8336670058409, w0=80.73826745447774, w1=5.564301572641499\n",
      "SGD iter. 472/499: loss=36.4863819345319, w0=86.71795426030974, w1=14.861394682360263\n",
      "SGD iter. 473/499: loss=122.14065685572018, w0=75.77730328705381, w1=18.584589100276993\n",
      "SGD iter. 474/499: loss=9.526312652257422, w0=78.8327552011268, w1=14.565563501710994\n",
      "SGD iter. 475/499: loss=3.5528264891013817, w0=76.96680505192148, w1=15.198508006893075\n",
      "SGD iter. 476/499: loss=42.87602460961977, w0=70.48463688706897, w1=4.66884460228154\n",
      "SGD iter. 477/499: loss=3.7343318570931423, w0=72.39765680854164, w1=4.190964464397763\n",
      "SGD iter. 478/499: loss=26.529920901656467, w0=77.49660988575498, w1=7.565993045546997\n",
      "SGD iter. 479/499: loss=3.4014759341930403, w0=79.32238271267217, w1=10.531786717017024\n",
      "SGD iter. 480/499: loss=38.12961836353952, w0=73.20952527966519, w1=20.285641032058805\n",
      "SGD iter. 481/499: loss=1.8811126630759418, w0=71.85177331048436, w1=20.067155981447687\n",
      "SGD iter. 482/499: loss=5.169090470819224, w0=74.10248623340519, w1=19.83400776992919\n",
      "SGD iter. 483/499: loss=15.119612097139274, w0=77.95180043923413, w1=21.342283643980487\n",
      "SGD iter. 484/499: loss=2.575290875058975, w0=79.54044295961366, w1=19.612301933573256\n",
      "SGD iter. 485/499: loss=17.812645891457294, w0=75.36235811442104, w1=16.986696984075696\n",
      "SGD iter. 486/499: loss=0.11944201087134461, w0=75.70448845603651, w1=16.633541658578007\n",
      "SGD iter. 487/499: loss=1.1631510287062485, w0=74.63683307711871, w1=16.71689621309841\n",
      "SGD iter. 488/499: loss=17.9615191060509, w0=70.44132491672504, w1=12.904157966498047\n",
      "SGD iter. 489/499: loss=5.274195797077285, w0=72.71480504224533, w1=15.022794102973972\n",
      "SGD iter. 490/499: loss=3.1216382152291366, w0=74.46386348921746, w1=13.897321265240988\n",
      "SGD iter. 491/499: loss=39.07821603548635, w0=68.27543463249005, w1=18.883623458776864\n",
      "SGD iter. 492/499: loss=42.70481340132338, w0=74.74464765520749, w1=10.181367878097776\n",
      "SGD iter. 493/499: loss=0.046650354436262705, w0=74.53083150205825, w1=9.796141614147032\n",
      "SGD iter. 494/499: loss=15.946485493776697, w0=78.4840018479833, w1=14.821144461827693\n",
      "SGD iter. 495/499: loss=21.02491975768553, w0=73.94479251567311, w1=12.96799640315547\n",
      "SGD iter. 496/499: loss=21.34356423912699, w0=69.37131539707457, w1=10.122715347975003\n",
      "SGD iter. 497/499: loss=3.175734036722557, w0=67.60716705977747, w1=8.517082384499998\n",
      "SGD iter. 498/499: loss=130.88002222913147, w0=78.93246713459, w1=21.0947923354231\n",
      "SGD iter. 499/499: loss=45.07075892182777, w0=72.2864650473656, w1=18.38153877864048\n",
      "SubSGD: execution time=0.012 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f6e354407f8403ab3dfd423398a8ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
